# å¤‡ä»½çŠ¶æ€

## ç«¯ç‚¹ä¿¡æ¯

```http
GET /database/{db_name}/backup/{backup_id}/status
Authorization: Bearer your_api_key
```

è·å–æŒ‡å®šå¤‡ä»½ä»»åŠ¡çš„çŠ¶æ€ä¿¡æ¯ã€‚

```http
GET /database/{db_name}/backup/tasks
Authorization: Bearer your_api_key
```

è·å–æ•°æ®åº“çš„æ‰€æœ‰å¤‡ä»½ä»»åŠ¡çŠ¶æ€åˆ—è¡¨ã€‚

## æƒé™è¦æ±‚
- `backup_status` æƒé™
- å¯¹ç›®æ ‡æ•°æ®åº“çš„ `read` æƒé™

## è¯·æ±‚

### å•ä¸ªå¤‡ä»½çŠ¶æ€

#### è¯·æ±‚å¤´
| å¤´éƒ¨ | å€¼ | å¿…å¡« |
|------|-----|------|
| `Authorization` | `Bearer your_api_key` | æ˜¯ |

#### è·¯å¾„å‚æ•°
| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| `db_name` | string | æ˜¯ | æ•°æ®åº“åç§° |
| `backup_id` | string | æ˜¯ | å¤‡ä»½ä»»åŠ¡ID |

### å¤‡ä»½ä»»åŠ¡åˆ—è¡¨

#### è¯·æ±‚å¤´
| å¤´éƒ¨ | å€¼ | å¿…å¡« |
|------|-----|------|
| `Authorization` | `Bearer your_api_key` | æ˜¯ |

#### è·¯å¾„å‚æ•°
| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| `db_name` | string | æ˜¯ | æ•°æ®åº“åç§° |

## å“åº”

### å•ä¸ªå¤‡ä»½çŠ¶æ€å“åº”

**çŠ¶æ€ç :** `200 OK`

```json
{
  "status": "completed",
  "filename": "admin_my_database_backup_20240120_143000.sql.gz",
  "size": 1572864,
  "size_human": "1.50 MB",
  "created_time": "2024-01-20T14:30:00",
  "modified_time": "2024-01-20T14:35:00",
  "message": "å¤‡ä»½å·²å®Œæˆ"
}
```

**å¤‡ä»½è¿›è¡Œä¸­:**
```json
{
  "status": "processing",
  "filename": "admin_my_database_backup_20240120_143000.sql.gz",
  "message": "å¤‡ä»½ä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­ï¼Œè¯·ç¨ååˆ·æ–°æŸ¥çœ‹"
}
```

### å¤‡ä»½ä»»åŠ¡åˆ—è¡¨å“åº”

**çŠ¶æ€ç :** `200 OK`

```json
{
  "database": "my_database",
  "task_count": 3,
  "tasks": [
    {
      "backup_id": "admin_my_database_backup_20240120_143000.sql.gz",
      "filename": "admin_my_database_backup_20240120_143000.sql.gz",
      "status": "completed",
      "database": "my_database",
      "size": 1572864,
      "size_human": "1.50 MB",
      "created_time": "2024-01-20T14:30:00",
      "message": "å¤‡ä»½å·²å®Œæˆ"
    },
    {
      "backup_id": "admin_my_database_backup_20240120_144500.sql.gz",
      "filename": "admin_my_database_backup_20240120_144500.sql.gz",
      "status": "processing",
      "database": "my_database",
      "message": "å¤‡ä»½ä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­"
    }
  ]
}
```

### å“åº”å­—æ®µè¯´æ˜

#### å•ä¸ªå¤‡ä»½çŠ¶æ€
| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `status` | string | å¤‡ä»½çŠ¶æ€ |
| `filename` | string | å¤‡ä»½æ–‡ä»¶å |
| `size` | integer | æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰ |
| `size_human` | string | äººç±»å¯è¯»çš„æ–‡ä»¶å¤§å° |
| `created_time` | string | åˆ›å»ºæ—¶é—´ |
| `modified_time` | string | ä¿®æ”¹æ—¶é—´ |
| `message` | string | çŠ¶æ€æ¶ˆæ¯ |

#### ä»»åŠ¡åˆ—è¡¨
| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `database` | string | æ•°æ®åº“åç§° |
| `task_count` | integer | ä»»åŠ¡æ•°é‡ |
| `tasks` | array | å¤‡ä»½ä»»åŠ¡åˆ—è¡¨ |

#### ä»»åŠ¡ä¿¡æ¯
| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `backup_id` | string | å¤‡ä»½ä»»åŠ¡ID |
| `filename` | string | å¤‡ä»½æ–‡ä»¶å |
| `status` | string | å¤‡ä»½çŠ¶æ€ |
| `database` | string | æ•°æ®åº“åç§° |
| `size` | integer | æ–‡ä»¶å¤§å°ï¼ˆå¦‚æœ‰ï¼‰ |
| `size_human` | string | äººç±»å¯è¯»çš„æ–‡ä»¶å¤§å° |
| `created_time` | string | åˆ›å»ºæ—¶é—´ |
| `message` | string | çŠ¶æ€æ¶ˆæ¯ |

## ä½¿ç”¨ç¤ºä¾‹

### cURL ç¤ºä¾‹

**è·å–å•ä¸ªå¤‡ä»½çŠ¶æ€:**
```bash
curl -X GET https://dbapi.muzilix.cn/database/my_database/backup/admin_my_database_backup_20240120_143000.sql.gz/status \
  -H "Authorization: Bearer your_api_key"
```

**è·å–å¤‡ä»½ä»»åŠ¡åˆ—è¡¨:**
```bash
curl -X GET https://dbapi.muzilix.cn/database/my_database/backup/tasks \
  -H "Authorization: Bearer your_api_key"
```

### Python ç¤ºä¾‹
```python
def get_backup_status(api_key, db_name, backup_id):
    """è·å–å¤‡ä»½ä»»åŠ¡çŠ¶æ€"""
    url = f"https://dbapi.muzilix.cn/database/{db_name}/backup/{backup_id}/status"
    headers = {"Authorization": f"Bearer {api_key}"}
    
    response = requests.get(url, headers=headers)
    return response.json()

def get_backup_tasks(api_key, db_name):
    """è·å–å¤‡ä»½ä»»åŠ¡åˆ—è¡¨"""
    url = f"https://dbapi.muzilix.cn/database/{db_name}/backup/tasks"
    headers = {"Authorization": f"Bearer {api_key}"}
    
    response = requests.get(url, headers=headers)
    return response.json()

def monitor_backup_progress(api_key, db_name, backup_id, max_attempts=30, interval=10):
    """ç›‘æ§å¤‡ä»½è¿›åº¦"""
    import time
    
    for attempt in range(max_attempts):
        status = get_backup_status(api_key, db_name, backup_id)
        
        if status["status"] == "completed":
            print(f"âœ… å¤‡ä»½å®Œæˆ: {status['filename']} ({status['size_human']})")
            return status
        elif status["status"] == "failed":
            print(f"âŒ å¤‡ä»½å¤±è´¥: {status.get('message', 'æœªçŸ¥é”™è¯¯')}")
            return status
        else:
            print(f"â³ å¤‡ä»½è¿›è¡Œä¸­... ({attempt + 1}/{max_attempts}) - {status['message']}")
            
            if attempt < max_attempts - 1:
                time.sleep(interval)
    
    print("â° å¤‡ä»½ç›‘æ§è¶…æ—¶")
    return {"status": "timeout", "message": "ç›‘æ§è¶…æ—¶"}

# ä½¿ç”¨ç¤ºä¾‹
# ç›‘æ§ç‰¹å®šå¤‡ä»½
backup_id = "admin_production_backup_20240120_143000.sql.gz"
status = monitor_backup_progress("your_api_key", "production_db", backup_id)

# æŸ¥çœ‹æ‰€æœ‰å¤‡ä»½ä»»åŠ¡
tasks = get_backup_tasks("your_api_key", "production_db")
print(f"æ•°æ®åº“ {tasks['database']} æœ‰ {tasks['task_count']} ä¸ªå¤‡ä»½ä»»åŠ¡")

for task in tasks["tasks"]:
    status_icon = "âœ…" if task["status"] == "completed" else "â³" if task["status"] == "processing" else "âŒ"
    size_info = f" - {task['size_human']}" if "size_human" in task else ""
    print(f"{status_icon} {task['filename']}{size_info}")
```

## å¤‡ä»½çŠ¶æ€è¯´æ˜

### çŠ¶æ€ç±»å‹
- `started` - å¤‡ä»½ä»»åŠ¡å·²å¯åŠ¨
- `processing` - å¤‡ä»½æ‰§è¡Œä¸­
- `completed` - å¤‡ä»½å®Œæˆ
- `failed` - å¤‡ä»½å¤±è´¥
- `timeout` - å¤‡ä»½è¶…æ—¶

### çŠ¶æ€è½¬æ¢
```
started â†’ processing â†’ completed
                â†“
              failed
```

## å¤‡ä»½ç›‘æ§å·¥å…·

### å®æ—¶ç›‘æ§é¢æ¿
```python
def create_backup_dashboard(api_key, db_names):
    """åˆ›å»ºå¤‡ä»½ç›‘æ§é¢æ¿"""
    print("ğŸ” å¤‡ä»½ç›‘æ§é¢æ¿")
    print("=" * 80)
    
    for db_name in db_names:
        tasks = get_backup_tasks(api_key, db_name)
        
        if "error" in tasks:
            print(f"âŒ {db_name}: è·å–ä»»åŠ¡å¤±è´¥ - {tasks['error']}")
            continue
        
        completed = [t for t in tasks["tasks"] if t["status"] == "completed"]
        processing = [t for t in tasks["tasks"] if t["status"] == "processing"]
        failed = [t for t in tasks["tasks"] if t["status"] == "failed"]
        
        print(f"\nğŸ“Š æ•°æ®åº“: {db_name}")
        print(f"   æ€»è®¡: {tasks['task_count']} ä¸ªä»»åŠ¡")
        print(f"   âœ… å®Œæˆ: {len(completed)}")
        print(f"   â³ è¿›è¡Œä¸­: {len(processing)}")
        print(f"   âŒ å¤±è´¥: {len(failed)}")
        
        # æ˜¾ç¤ºæœ€æ–°å¤‡ä»½
        if completed:
            latest = max(completed, key=lambda x: x.get("created_time", ""))
            print(f"   æœ€æ–°å¤‡ä»½: {latest['filename']} ({latest.get('size_human', 'N/A')})")

# ä½¿ç”¨ç¤ºä¾‹
databases = ["production_db", "analytics_db", "backup_db"]
create_backup_dashboard("your_api_key", databases)
```

### å¤‡ä»½å¥åº·æ£€æŸ¥
```python
def check_backup_health(api_key, db_name, expected_frequency_hours=24):
    """æ£€æŸ¥å¤‡ä»½å¥åº·çŠ¶å†µ"""
    from datetime import datetime, timedelta
    
    tasks = get_backup_tasks(api_key, db_name)
    
    if "error" in tasks:
        return {"healthy": False, "error": tasks["error"]}
    
    completed_backups = [t for t in tasks["tasks"] if t["status"] == "completed"]
    
    if not completed_backups:
        return {"healthy": False, "message": "æ²¡æœ‰æ‰¾åˆ°å®Œæˆçš„å¤‡ä»½"}
    
    # æ‰¾åˆ°æœ€æ–°å¤‡ä»½
    latest_backup = max(completed_backups, key=lambda x: x.get("created_time", ""))
    latest_time = datetime.fromisoformat(latest_backup["created_time"].replace('Z', '+00:00'))
    
    # æ£€æŸ¥å¤‡ä»½æ—¶æ•ˆæ€§
    time_since_last_backup = datetime.now() - latest_time
    is_fresh = time_since_last_backup < timedelta(hours=expected_frequency_hours)
    
    health_status = {
        "healthy": is_fresh,
        "latest_backup": latest_backup["filename"],
        "backup_time": latest_backup["created_time"],
        "hours_since_backup": round(time_since_last_backup.total_seconds() / 3600, 1),
        "expected_frequency_hours": expected_frequency_hours,
        "total_backups": len(completed_backups)
    }
    
    if not is_fresh:
        health_status["warning"] = f"å¤‡ä»½å·²è¿‡æœŸ {health_status['hours_since_backup']} å°æ—¶"
    
    return health_status

# ä½¿ç”¨ç¤ºä¾‹
health = check_backup_health("your_api_key", "production_db", expected_frequency_hours=24)
if health["healthy"]:
    print(f"âœ… å¤‡ä»½å¥åº·: æœ€æ–°å¤‡ä»½ {health['latest_backup']} ({health['hours_since_backup']} å°æ—¶å‰)")
else:
    print(f"âš ï¸  {health['warning']}")
```

## é”™è¯¯å¤„ç†

### å¤‡ä»½ä¸å­˜åœ¨
```json
{
  "status": "not_found",
  "message": "å¤‡ä»½ä»»åŠ¡ä¸å­˜åœ¨"
}
```

### æƒé™ä¸è¶³
```json
{
  "error": "æ²¡æœ‰è®¿é—®è¯¥å¤‡ä»½çš„æƒé™"
}
```

## ç›¸å…³é“¾æ¥

- [å¤‡ä»½æ¢å¤æ€»è§ˆ](../backup-recovery/index.md)
- [åˆ›å»ºå¤‡ä»½](backup-database.md)
- [å¤‡ä»½åˆ—è¡¨](list-backups.md)
- [ä¸‹è½½å¤‡ä»½](download-backup.md)
- [åˆ é™¤å¤‡ä»½](delete-backup.md)